{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_encoding(path, outfile):\n",
    "    dataMat = []; labelMat = []\n",
    "    dataList = []; labelList = []\n",
    "    feature_val = []\n",
    "    encoded_20D = []\n",
    "    result_1D = []\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if not os.path.isdir(file):  #open when it is a folder\n",
    "            f = open(path+'/'+file,'r')\n",
    "            lines = f.readlines()  # return a list\n",
    "            \n",
    "            for line in lines:\n",
    "                #separate the sequences and labels\n",
    "                l_line = line.strip()\n",
    "                line_list = l_line.split(' ')\n",
    "                while '' in line_list:\n",
    "                    line_list.remove('')\n",
    "\n",
    "                dataList.append(line_list[0])\n",
    "                labelList.append(line_list[1])\n",
    "    '''\n",
    "    for seq in dataList:\n",
    "        for i in range(len(seq)):\n",
    "            # Encode each amino acid in the sequence into a sequence of 20 as 0，1 binaries\n",
    "            binary_str_20D = dic_encoded[seq[i]]\n",
    "            for j in range(len(binary_str_20D)):\n",
    "                temp_v = int(binary_str_20D[j])\n",
    "                feature_val.append(temp_v)\n",
    "    step = 180\n",
    "    encoded_20D = [feature_val[i:i+step] for i in range(0,len(feature_val),step)]\n",
    "\n",
    "    '''\n",
    "    \n",
    "    for i in range(len(labelList)):\n",
    "        result_1D.append(int(labelList[i]))\n",
    "    # dataMat = np.array(encoded_20D) #dataMat as a X feature matrix\n",
    "    \n",
    "    dataMat = np.array(dataList) #dataMat as a X feature matrix\n",
    "    labelMat = np.asarray(result_1D) #labelMat as a y label matrix\n",
    "    # Combine the feature matrix and the label matrix into one matrix\n",
    "    window_Mat = np.column_stack((dataMat, labelMat))\n",
    "    np.random.shuffle(window_Mat)\n",
    "\n",
    "    np.savetxt(outfile,window_Mat,fmt='%s')\n",
    "    f.close()\n",
    "    return window_Mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSetbyKFold(window_Mat,split_size,outdir):\n",
    "    if not os.path.exists(outdir): #if not outdir, makedir\n",
    "        os.makedirs(outdir)\n",
    "    train_all = [];\n",
    "    test_all = []\n",
    "    each_split_tr = []\n",
    "    each_split_te = []\n",
    "    count_split = 0\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    for train_index, test_index in kf.split(window_Mat):\n",
    "        count_split += 1\n",
    "        for index in train_index:\n",
    "            each_split_tr.append(list(window_Mat[index]))\n",
    "        array_ = np.array(each_split_tr)\n",
    "        np.savetxt(outdir + \"/train_\" + str(count_split) + '.txt',array_, fmt=\"%s\", delimiter='\\t')  # output each piece of data\n",
    "        train_all.append(each_split_tr)  # Add each piece of data to a list '[[[],[],...[]]]' 3-D list\n",
    "        each_split_tr = []\n",
    "\n",
    "        for index in test_index:\n",
    "            each_split_te.append(list(window_Mat[index]))\n",
    "        array_ = np.array(each_split_te)\n",
    "        np.savetxt(outdir + \"/test_\" + str(count_split) + '.txt',array_, fmt=\"%s\", delimiter='\\t')  # output each piece of data\n",
    "        test_all.append(each_split_te)  # Add each piece of data to a list\n",
    "        each_split_te = []\n",
    "\n",
    "    #train_all = train_all[0]\n",
    "    #test_all = test_all[0]\n",
    "    return train_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.0; TN = 0.0; FP = 0.0; FN = 0.0\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.0\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.0\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.0\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.0\n",
    "    print(TP)\n",
    "    print(FN)\n",
    "    print(TN)\n",
    "    print(FP)\n",
    "    \n",
    "    if ((TP+FN) == 0):\n",
    "        SN = 0\n",
    "        SP = 0\n",
    "    elif ((FP+FN) == 0):\n",
    "        SN = 0\n",
    "        SP = 0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return SN,SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(clf,clfname,train_X, train_y, test_X, test_y,i):#X:feature matrix，y:label matrix\n",
    "    # train with train set\n",
    "    print(\" training begin...\")\n",
    "    clf = clf.fit(train_X,train_y)\n",
    "    print(\" training end.\")\n",
    "    #==========================================================================\n",
    "    # test with validation set\n",
    "    print(\" test begin.\")\n",
    "    predict_ = clf.predict(test_X) #return type is float64\n",
    "    proba = clf.predict_proba(test_X)[:,1] #return type is float64\n",
    "    score_ = clf.score(test_X, test_y)\n",
    "    \n",
    "    # Report\n",
    "    sk_report = classification_report(\n",
    "    digits=6,\n",
    "    y_true=test_y, \n",
    "    y_pred=clf.predict(test_X))\n",
    "    print(sk_report)\n",
    "    \n",
    "    print(\" test end.\")\n",
    "    \n",
    "    #==========================================================================\n",
    "    \n",
    "    ACC = accuracy_score(test_y, predict_)\n",
    "    SN, SP = performance(test_y, predict_)\n",
    "    MCC = matthews_corrcoef(test_y, predict_)\n",
    "    #AUC = roc_auc_score(test_y, proba)\n",
    "    AUC = 0\n",
    "    \n",
    "    # Model Evaluation\n",
    "    #==========================================================================\n",
    "    #save output\n",
    "    \n",
    "    eval_output = []\n",
    "    eval_output.append(ACC);eval_output.append(SN);eval_output.append(AUC)\n",
    "    eval_output.append(SP);eval_output.append(MCC)\n",
    "    eval_output.append(score_)\n",
    "    eval_output = np.array(eval_output,dtype=float)\n",
    "    \n",
    "    np.savetxt(\"proba.data\",proba,fmt=\"%f\",delimiter=\"\\t\")\n",
    "    np.savetxt(\"test_y.data\",test_y,fmt=\"%f\",delimiter=\"\\t\")\n",
    "    np.savetxt(\"predict.data\",predict_,fmt=\"%f\",delimiter=\"\\t\")\n",
    "    #np.savetxt(\"eval_output.data\",eval_output,fmt=\"%f\",delimiter=\"\\t\")\n",
    "    print(\"Wrote results to output.data...EOF...\")\n",
    "    # ==========================================================================\n",
    "    # save Model\n",
    "    os.chdir(\"/home/fyp1920/Desktop/coding/ML_Model\")\n",
    "\n",
    "    joblib.dump(clf,'train_'+clfname+str(i)+'.model')\n",
    "    return ACC,SN,SP,MCC,AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_fun used to find the average value of the values in the list,\n",
    "# mainly ACC mean,SP mean and SN mean, to evaluate the model\n",
    "def mean_fun(onelist):\n",
    "    count = 0\n",
    "    for i in onelist:\n",
    "        count += i\n",
    "    return float(count/len(onelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(clf, clfname, curdir, train_all, test_all):\n",
    "    os.chdir(curdir)\n",
    "    cur_path = curdir\n",
    "    ACCs = [];SNs = [];SPs = [];MCCs = [];AUCs = []\n",
    "\n",
    "    for i in range(len(train_all)):\n",
    "        print('----- Round ', i, ' -----' )\n",
    "        print('Start Time: ', datetime.datetime.now())\n",
    "        \n",
    "        os.chdir(cur_path)\n",
    "        train_data = train_all[i]; train_X = []; train_y = []\n",
    "        test_data = test_all[i]; test_X = []; test_y = []\n",
    "\n",
    "        #Divide train_all into train_X and train_y\n",
    "        for eachline_train in train_data:\n",
    "            one_train = eachline_train\n",
    "            one_train_format = []\n",
    "            for index in range(0, len(one_train) - 1):\n",
    "                one_train_format.append(float(one_train[index]))\n",
    "            train_X.append(one_train_format)\n",
    "            train_y.append(int(one_train[-1]))\n",
    "\n",
    "        #Divide test_all into test_X and test_y\n",
    "        for eachline_test in test_data:\n",
    "            one_test = eachline_test\n",
    "            one_test_format = []\n",
    "            for index in range(0, len(one_test) - 1):\n",
    "                one_test_format.append(float(one_test[index]))\n",
    "            test_X.append(one_test_format)\n",
    "            test_y.append(int(one_test[-1]))\n",
    "        # ======================================================================\n",
    "        # classifier start here\n",
    "        if not os.path.exists(clfname):\n",
    "            os.mkdir(clfname)\n",
    "        out_path = clfname + \"/\" + clfname + \"_00\" + str(i)  # the folder that save result of each fold\n",
    "        if not os.path.exists(out_path):\n",
    "            os.mkdir(out_path)\n",
    "        os.chdir(out_path)\n",
    "        ACC, SN, SP, MCC, AUC = classifier(clf, clfname, train_X, train_y, test_X, test_y,i)\n",
    "        ACCs.append(ACC)\n",
    "        SNs.append(SN)\n",
    "        SPs.append(SP)\n",
    "        MCCs.append(MCC)\n",
    "        AUCs.append(AUC)\n",
    "        \n",
    "        print('End Time: ', datetime.datetime.now())\n",
    "        print('---------------')\n",
    "        print('')\n",
    "        \n",
    "    # ======================================================================\n",
    "    ACC_mean = mean_fun(ACCs)\n",
    "    SN_mean = mean_fun(SNs)\n",
    "    SP_mean = mean_fun(SPs)\n",
    "    MCC_mean = mean_fun(MCCs)\n",
    "    AUC_mean = mean_fun(AUCs)\n",
    "    # ==========================================================================\n",
    "    # output experiment result\n",
    "    (\"/home/fyp1920/Desktop/coding/\")\n",
    "    os.system(\"echo `date`'\" + str(clf) + \"' >> log.out\")\n",
    "    os.system(\"echo ACC_mean=\" + str(ACC_mean) + \" >> log.out\")\n",
    "    os.system(\"echo SN_mean=\" + str(SN_mean) + \" >> log.out\")\n",
    "    os.system(\"echo SP_mean=\" + str(SP_mean) + \" >> log.out\")\n",
    "    os.system(\"echo MCC_mean=\" + str(MCC_mean) + \" >> log.out\")\n",
    "    os.system(\"echo AUC_mean=\" + str(AUC_mean) + \" >> log.out\")\n",
    "    \n",
    "    return ACC_mean, SN_mean, SP_mean, MCC_mean, AUC_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate dataset end and cross validation start\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/oscarkuan/coding/fyp_ecgid/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92b977d07ebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#ACC_mean, SN_mean, SP_mean, MCC_mean, AUC_mean = crossValidation(clf, clfname, curdir, train_all, test_all)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# performace_list = [ACC_mean, SN_mean, SP_mean, MCC_mean, AUC_mean]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3cfe8bcfe95a>\u001b[0m in \u001b[0;36mcrossValidation\u001b[0;34m(clf, clfname, curdir, train_all, test_all)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcur_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mACCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mSNs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mSPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mMCCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mAUCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/oscarkuan/coding/fyp_ecgid/'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = 'LABELED_DATASET'\n",
    "    outfile = 'seq_encoded.txt'\n",
    "    outdir = 'KFold'\n",
    "    a = []\n",
    "    # encode the original dataset\n",
    "    window_Mat = seq_encoding(path,outfile)\n",
    "\n",
    "    # split the feature matrix into N fold\n",
    "    train_all, test_all = splitDataSetbyKFold(window_Mat, 100, outdir)\n",
    "\n",
    "    print(\"Generate dataset end and cross validation start\")\n",
    "\n",
    "    clf = svm.SVC(C=1, kernel='rbf', gamma=0.05, probability=True)\n",
    "    curdir = '/home/fyp1920/Desktop/coding'\n",
    "    clfname = 'SVM'\n",
    "    #ACC_mean, SN_mean, SP_mean, MCC_mean, AUC_mean = crossValidation(clf, clfname, curdir, train_all, test_all)\n",
    "    crossValidation(clf, clfname, curdir, train_all, test_all)\n",
    "\n",
    "    # performace_list = [ACC_mean, SN_mean, SP_mean, MCC_mean, AUC_mean]\n",
    "    # performace_set = ['ACC_mean', 'SN_mean', 'SP_mean', 'MCC_mean', 'AUC_mean']\n",
    "    # plt.plot(performace_set, performace_list, 'r-o', label='Performance')\n",
    "    # plt.legend()\n",
    "    # plt.title('MHC Prediction by SVM')\n",
    "    # plt.xlabel('Name of Evaluation')\n",
    "    # plt.ylabel('Performance')\n",
    "    # plt.show()\n",
    "    # plt.savefig('SVM_10fold.png')\n",
    "    #print('MCC_mean', '\\t', 'AUC_mean', '\\t', 'ACC_mean', '\\t', 'SN_mean', '\\t', 'SP_mean')\n",
    "    #print(MCC_mean, AUC_mean, ACC_mean, SN_mean, SP_mean)  # 将ACC均值，SP均值，SN均值都输出到控制台\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
